{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project and data are based on a free, online course of machine learning https://www.coursera.org/learn/machine-learning. I wholeheartedly recommend this! \n",
    "\n",
    "## I will show how do it in Python:\n",
    "    + apply SVM (support vector machine) to spam classification,\n",
    "    + use regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "\n",
    "# ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# write packages and python version to file\n",
    "'''\n",
    "! python -m pip list > packages_versions.txt\n",
    "# a append to file\n",
    "with open('packages_versions.txt', 'a') as f:\n",
    "    f.write('Python version ' + str(sys.version))\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    '''\n",
    "    Removes html tags.\n",
    "    '''\n",
    "    return re.sub('<[^<>]+>', ' ', text)\n",
    "assert remove_html_tags('<a href=\"onet.com\">deal with it</a>') == ' deal with it '\n",
    "\n",
    "def normalizing_URLs(text):\n",
    "    '''\n",
    "    Replaces URL to \" httpaddr \".\n",
    "    '''\n",
    "    return re.sub('(http|https|ftp)://[^\\s]*', ' httpaddr ', text)\n",
    "\n",
    "assert normalizing_URLs('herehttps://en.wikipedia.org/wiki/URL') == 'here httpaddr ' \n",
    "\n",
    "def normalizing_emails(text):\n",
    "    '''\n",
    "    Replaces email adress to \" emailaddr \".\n",
    "    '''\n",
    "    return re.sub('[^\\s]+@[^\\s]+', ' emailaddr ', text)\n",
    "\n",
    "assert normalizing_emails('contact awokado@gmail.com') == 'contact  emailaddr '\n",
    "\n",
    "def normalize_dolar(text):\n",
    "    '''\n",
    "    Replaces $ sign to \" dolar \".\n",
    "    '''\n",
    "    return re.sub('[$]+', ' dollar ', text)\n",
    "\n",
    "assert normalize_dolar('less$$$bargain$') == 'less dollar bargain dollar '\n",
    "\n",
    "def normalize_numbers(text):\n",
    "    '''\n",
    "    Replaces $ sign to \" number \".\n",
    "    '''\n",
    "    return re.sub('[\\d]+', ' number ', text)\n",
    "\n",
    "assert normalize_numbers('for 3 day') == 'for  number  day'\n",
    "\n",
    "def remove_punct(text):\n",
    "    '''\n",
    "    Removes all punctuation marks.\n",
    "    '''\n",
    "    translator = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "    return text.translate(translator)\n",
    "\n",
    "assert remove_punct('only#today!!!') == 'only today   '\n",
    "\n",
    "def remove_multi_spaces(text):\n",
    "    '''\n",
    "    Replaces multi spaces to one.\n",
    "    '''\n",
    "    return re.sub(' +', ' ', text)\n",
    "\n",
    "def proccess_email(text):\n",
    "    '''\n",
    "    Normalizes email.\n",
    "    '''\n",
    "    text = text.lower()\n",
    "    text = remove_html_tags(text)\n",
    "    text = normalizing_URLs(text)\n",
    "    text = normalizing_emails(text)\n",
    "    text = normalize_dolar(text)\n",
    "    text = normalize_numbers(text)\n",
    "    text = remove_punct(text)\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = remove_multi_spaces(text)\n",
    "    return text\n",
    "\n",
    "def email_to_features(email_name, ps, vocab):\n",
    "    '''\n",
    "    Sets 1 at right position, when word from vocab occurs in email.\n",
    "    '''\n",
    "    with open(email_name, 'r') as file:\n",
    "        email = file.read()\n",
    "        email = proccess_email(email).split()\n",
    "        email = [ps.stem(w) for w in email]\n",
    "        email = sorted(set(email), key=email.index)\n",
    "    ind_list = []\n",
    "    for word in email:\n",
    "        try:\n",
    "            ind_list.append(vocab_dict[word])\n",
    "        except KeyError:\n",
    "            pass\n",
    "    init = np.zeros((1,1899))\n",
    "    for ind in ind_list:\n",
    "        init[0,ind] = 1\n",
    "    return init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use porterStemmer to treat program and programmer as 'program'\n",
    "ps = PorterStemmer() \n",
    "\n",
    "with open('vocab.txt', 'r') as file:\n",
    "    vocab = file.read().replace('\\n', ' ')\n",
    "    vocab = vocab.replace('\\t', ' ')\n",
    "    vocab = remove_multi_spaces(vocab)\n",
    "    vocab = vocab.split()\n",
    "    vocab_dict = {}\n",
    "    for i, ind in enumerate(range(1, len(vocab), 2)):\n",
    "        vocab_dict[vocab[ind]] = i\n",
    "\n",
    "rev_vocab_dict = dict(zip(vocab_dict.values(), vocab_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "data = scipy.io.loadmat('spamTrain.mat')\n",
    "# X indicates which words from spam vocabulary list are used in email.\n",
    "X = data['X']\n",
    "Y = data['y'].flatten()\n",
    "from sklearn.svm import SVC\n",
    "model = SVC(kernel='linear', C=0.1)\n",
    "model.fit(X, Y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word        weight\n",
      "******************\n",
      "our         0.501\n",
      "click       0.466\n",
      "remov       0.423\n",
      "guarante    0.384\n",
      "visit       0.368\n",
      "basenumb    0.345\n",
      "dollar      0.324\n",
      "will        0.270\n",
      "price       0.267\n",
      "pleas       0.261\n",
      "most        0.257\n",
      "nbsp        0.254\n",
      "lo          0.253\n",
      "ga          0.248\n",
      "hour        0.246\n"
     ]
    }
   ],
   "source": [
    "# Lets find words, which are most common in spam.\n",
    "coef = model.coef_.flatten()\n",
    "sorted_ind = np.argsort(coef)\n",
    "top_15 = sorted_ind[:-16:-1]\n",
    "print('word        weight')\n",
    "print('*' * 18)\n",
    "for top in top_15:\n",
    "    print('{:10}  {:.3f}'.format(rev_vocab_dict[top], coef[top]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value for emailSample1 0, it should be 0\n",
      "Predicted value for emailSample2 0, it should be 0\n",
      "Predicted value for spamSample1 1, it should be 1\n",
      "Predicted value for spamSample2 1, it should be 1\n"
     ]
    }
   ],
   "source": [
    "for i, name in enumerate(['emailSample1.txt', 'emailSample2.txt', 'spamSample1.txt', 'spamSample2.txt']):\n",
    "    features_arr = email_to_features(name, ps, vocab)\n",
    "    print('Predicted value for {} {}, it should be {}'.format(name[:-4], model.predict(features_arr)[0], i//2))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction on test set = 98.9%\n"
     ]
    }
   ],
   "source": [
    "data_test = scipy.io.loadmat('spamTest.mat')\n",
    "X_test = data_test['Xtest']\n",
    "Y_test = data_test['ytest'].flatten()\n",
    "print('Prediction on test set = {}%'.format(100 * np.mean(model.predict(X_test) == Y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
